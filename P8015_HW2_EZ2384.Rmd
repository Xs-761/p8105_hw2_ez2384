---
title: "P8015_HW2_EZ2384"
output: github_document
---

#### Load package
```{r, message=FALSE}
library(tidyverse)
library(tidyr)
library(dplyr)
library(readxl)
```

#### Problem 1

```{r, echo=FALSE}
raw_data = read.csv("../../Datasets/NYC_Subway.csv")
```


```{r, message=FALSE}
# Read and clean NYC Subway Data
  Subway =  read_csv("../../Datasets/NYC_Subway.csv") %>% janitor::clean_names() %>% 
            subset(select=c(line, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada)) %>%
            mutate(entry=case_match(entry, "YES"~"TRUE", "NO"~"FALSE"))
```
##### Dataset Description
* **Variables**
  * Division, Line, Station Name,	Station Latitude, Station Longitude, Route1-11, Entrance Type, Entry,	Exit Only, Vending,
    Staffing, Staff Hours, ADA, ADA Notes, Free Crossover, North South Street, East West Street, Corner, Entrance Latitude,
    Entrance Longitude, Station Location, Entrance Location
* **Discussion on Variables**
  * This dataset provides comprehensive information about subway stations in NYC, including spatial details, the subway routes they serve, and      station amenities such as vending machines, ADA accessibility, and whether a free crossover is available.
* **Data Cleaning Steps so far**
  * Up to this point, I have firstly use the janitor package `clean_names` function to turn the dataset into a "nicer" format including
    turning all variable names into lowercase and replace the empty spaces between them with an underscore and etc. Then I utilized the
    `subset()` function to keep only variables of interest. Finally, I used `mutate()` in combination with `case_match()` to convert all
    instances of YES into TRUE and all instances of NO into FALSE within the entry column.
* **Dimension of the dataset is given by** `r nrow(raw_data)`x`r ncol(raw_data)`
* **The Dataset was originally NOT tidy**
  * Although each variable has its own column and each observation has its own row, there are still empty cells, which makes the dataset
    not tidy.
* **There are** `r nrow(distinct(raw_data,Station.Name))` **distinct stations**
* **There are** `r sum(Subway$ada=="TRUE")` **stations that are ADA-compliant**
* **Proportion of station entrances/exits without vending machines is given by** `r sum(Subway$vending=="NO")/sum(Subway$vending=="YES")`

**Transposition of Route1:Route11**
```{r}

Subway_Transposed = Subway %>% mutate(across(route1:route11, as.character)) %>% 
    # convert route1:route11 into character data types in order to perform the following transposition
    pivot_longer(
          cols = route1:route11,     # specify route1:route11 as original columns to transpose from
          names_to = "route_number", # column for original column names
          values_to= "route_name",   # column for original column values
          values_drop_na = TRUE      # exclude rows with NA values in "values_to" column
                )

```

```{r, echo=FALSE}
A_stations = Subway_Transposed %>% filter(route_name=="A") %>% distinct(line)
common = intersect(A_stations, Subway_Transposed %>% filter(ada=="TRUE") %>% distinct(line))
```

* **There are** `r count( A_stations )` **distinct stations serving the A train.**
  * **Of these serving the A train,** `r count(common)` **are ADA compliant.**

#### Problem 2

**Read-in Trash Wheel dataset sheets and clean the datasets**
```{r}
# Mr.Trash-Wheel
  mr_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", range="A2:N655") %>% janitor:: clean_names() %>% mutate(sports_balls = round(as.numeric(sports_balls),0)) %>% filter(!is.na(dumpster))
# Prof.Trash-Wheel
  prof_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", sheet=2, range="A2:M123") %>% janitor::clean_names() %>% filter(!is.na(dumpster))
# Gwynnda Trash-Wheel
  gwynnda_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", sheet=4, range="A2:L266") %>% janitor::clean_names() %>% filter(!is.na(dumpster))
```

**Combine Datasets**
```{r}
# Firstly add an additional column specifying the DF origin
  mr_trash_wheel = mr_trash_wheel %>% mutate(source="Mr_Trash", year=as.numeric(year))
  prof_trash_wheel = prof_trash_wheel %>% mutate(source="Prof_Trash", year=as.numeric(year))
  gwynnda_trash_wheel = gwynnda_trash_wheel %>% mutate(source="Gwynnda_Trash", year=as.numeric(year))

  combined_trash = bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) %>% relocate(source, dumpster)
```

**Discussion on the Trash Wheel Dataset**

* Trash Wheel Excel File consists of 6 sheets, of which 4 contains trash wheel data and the rest contains explanatory information. For the trash wheel relevant sheets, each consists of descriptory columns such as
  * **Dumpster**: the dumpster number
  * **Year/Month/Date**: the datetime info for the trash collection
  * **Weight/Volume**: size and amount of trash collected at that specific collection task
  * **Plastic Bottles/Polystyrene/Cigarette Butts/Glass Bottles/Plastic Bags/Wrappers/Sports Balls**: different genres of trash collected at that specific collection task
  * **Homes Powered**: number of homes could be powered by converting the specific amount of trash at that collection task into electricity
* Number of observations in each dataframe after tidy processes:
  * **mr_trash_wheel**: 651 obs with 15 variables
  * **prof_trash_wheel**: 119 obs with 14 variables
  * **gwyna_trash_wheel**: 263 obs with 13 variables
  * **combined_trash**: 1033 obs with 15 variables
* Total weight of trash collected by Professor Trash Wheel is given by: `r sum(prof_trash_wheel$weight_tons, na.rm=TRUE)`
* Total number of cigarette butts collected by Gwynnda in June of 2022 is given by: `r gwynnda_trash_wheel %>% filter(month=="June" & year==2022) %>% summarise(total = sum(cigarette_butts, rm.na=TRUE)) %>% pull(total)`

#### Problem 3

* **Component 1**: Data Cleaning for the component datasets: bakers, bakes, results
```{r}
# Import, clean, tidy, and otherwise wrangle each of these datasets, remove observations containing empty values.
  bakers  = read.csv("../../Datasets/gbb_datasets/bakers.csv")  %>% janitor::clean_names()  %>% 
            mutate(baker_occupation=na_if(baker_occupation,""), hometown=na_if(hometown,"") ) %>% drop_na()
  bakes   = read.csv("../../Datasets/gbb_datasets/bakes.csv")   %>% janitor::clean_names()  %>%
            mutate(signature_bake=na_if(signature_bake,""), show_stopper=na_if(show_stopper,"")) %>% drop_na()
  results = read.csv("../../Datasets/gbb_datasets/results.csv", skip=2) %>% janitor::clean_names() %>%
            mutate(result=na_if(result,"")) %>% drop_na()

# Label variables that appears in multiple datasets
  bakers  = bakers %>% rename(name=baker_name, series_bakers=series, age_bakers=baker_age, 
                              occupation_bakers=baker_occupation, hometown_bakers=hometown)
  bakes   = bakes  %>% rename(name=baker, series_bakes=series, episode_bakes=episode, signature_bakes=signature_bake,
                              stopper_bakes=show_stopper)
  results = results%>% rename(name=baker, series_results=series, episode_results=episode, technical_results=technical,
                              result_results=result)

# Ensure unique identifier for each contestant
  bakers  = bakers %>% mutate(name=sub(" .*", "", name))
  
# Put unique identifier to the very front in each dataset
  bakers  = bakers %>% relocate(name)
  bakes   = bakes  %>% relocate(name)
  results = results%>% relocate(name)

```

```{r, include=FALSE}
# Notes for part1

#  Syntax and Coding Notes
  #  1. sub() syntax:   sub(pattern, replacement, string_to_search)
  #  2. RE expression:  " .*": search for the pattern of a space followed by one char followed by 0 or more occurrences of 
  #                     previous char(which is .)
  #  3. Value replacing rule in R:  NEW = OLD

#  Assignment-related Notes
  #  Data Structure(use str() to examine):    BAKERS: name(char), series(int), age(int), occupation(char), hometown(char)
  #                                           BAKES:  name(char), series(int), episode(int), signature(char)
  #                                           RESULTS:name(char), series(int), episode(int), technical(int), result(char)
```

* **Component 2**: Examine Completeness and Correctness across datasets
  * Datasets bakers, bakes, and results are all tidy after the data-cleaning procedures.
    After the cleaning processes, dataset bakers and results are complete.
    Dataset bakes is largely complete except it contains some "UNKNOWN" show_stoppers.
  * Matching status of key variable:
```{r, include=FALSE}
  unmatched_bakers_bakes   <- anti_join(bakers, bakes, by = "name")
  unmatched_bakers_results <- anti_join(bakers, results, by="name")
```
    * Contestants included in bakers dataset that are not included in the results dataset is given by `r unmatched_bakers_results$name`
    * Contestants included in bakers dataset that are not included in the bakes dataset is given by `r unmatched_bakers_bakes$name`

* **Component 3**: Merge into a single, final dataset. Organize so that obs and var are in meaningful orders.
```{r, message=FALSE}
  merged <- bakers %>% left_join(bakes, by = "name") %>% left_join(results, by = "name")
```

```{r}
  merged = merged %>% relocate(name, result_results, technical_results, starts_with("series"), starts_with("episode")) %>%
           arrange(name, result_results, technical_results)
```

* **Component 4**: Export the final result into a .csv file
```{r}
  write.csv(merged, "C:/Users/Twilight/Desktop/Columbia/Fall Semester 2024/Data Science I/HWs/p8105_hw2_ez2384/merged.csv")
```

* **Component 5**: Description of data-cleaning process and discussion of final dataset

  **clean the component datasets bakes, bakers, and results** 
1. used janitor package clean_names() to convert variable names into meaningful format
1. converted all empty strings in character data type columns into NA to faciliate my later removal of all NA records
1. dropped all NA records
1. added postfixes to each datasets to faciliate future merging
1. relocate name (the unique identifier) to the very front    
  **merge datasets** 
1. merge datasets by the unique identifier -- name
1. relocate variable locations by name, results, technical_results, series_number, episode_number, etc.
1. sort variables by name, results, technical_scores

* **Component 6**: Create a reader-friendly table showing the star baker or winner for each episode in Season 5-10.
                   Comment on this table - were there any predictable overall winners or any surprises?
```{r}
  winners = merged %>%  select(name, result_results, starts_with("series"), starts_with("episode")) %>%
                        filter(result_results %in% c("IN", "Runner-up", "STAR BAKER")) %>%
                        filter(series_bakes %in% c(5:10) & series_results %in% c(5:10) & series_bakers %in% c(5:10)) %>%
                        arrange()
  winner_frequency = winners %>% count(name) %>% arrange(desc(n))
  
  star_baker = winners %>% filter(result_results=="STAR BAKER")
  star_baker_names = distinct(star_baker, name)
```
* According to winner_frequency we can see that Kate is predominately winning (with 1197 occurrences of succeeding or winning).
  the second predominately winner has a drastically lower frequency of 198, therefore it is not surprising at all when we examine
  the list of star bakers in the star_baker_name dataset that we see Kate and Tom within the list.
* However, it is quite surprising to see that Marie appeared in the list given she only has a succeeding occurrences of 2

* **Component 7**: Import, clean, tidy, and organize viewers.csv file. Show the first 10 rows of this dataset.
                   What is the average viewership in Season1 and Season5 respectively?
```{r}
  viewers = read.csv("../../Datasets/gbb_datasets/viewers.csv") %>% janitor::clean_names() %>% arrange()
  # Ten observations given by
  head(viewers, n=10)
```

  * Average viewership in Season1 is given by `r mean(viewers$series_1, na.rm=TRUE)`
  * Average viewership in Season5 is given by `r mean(viewers$series_5)`
  