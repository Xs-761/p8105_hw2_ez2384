P8015_HW2_EZ2384
================

#### Load package

``` r
library(tidyverse)
library(tidyr)
library(dplyr)
library(readxl)
```

#### Problem 1

``` r
# Read and clean NYC Subway Data
  Subway =  read_csv("../../Datasets/NYC_Subway.csv") %>% janitor::clean_names() %>% 
            subset(select=c(line, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada)) %>%
            mutate(entry=case_match(entry, "YES"~"TRUE", "NO"~"FALSE"))
```

##### Dataset Description

- **Variables**
  - Division, Line, Station Name, Station Latitude, Station Longitude,
    Route1-11, Entrance Type, Entry, Exit Only, Vending, Staffing, Staff
    Hours, ADA, ADA Notes, Free Crossover, North South Street, East West
    Street, Corner, Entrance Latitude, Entrance Longitude, Station
    Location, Entrance Location
- **Discussion on Variables**
  - This dataset provides comprehensive information about subway
    stations in NYC, including spatial details, the subway routes they
    serve, and station amenities such as vending machines, ADA
    accessibility, and whether a free crossover is available.
- **Data Cleaning Steps so far**
  - Up to this point, I have firstly use the janitor package
    `clean_names` function to turn the dataset into a “nicer” format
    including turning all variable names into lowercase and replace the
    empty spaces between them with an underscore and etc. Then I
    utilized the `subset()` function to keep only variables of interest.
    Finally, I used `mutate()` in combination with `case_match()` to
    convert all instances of YES into TRUE and all instances of NO into
    FALSE within the entry column.
- **Dimension of the dataset is given by** 1868x32
- **The Dataset was originally NOT tidy**
  - Although each variable has its own column and each observation has
    its own row, there are still empty cells, which makes the dataset
    not tidy.
- **There are** 356 **distinct stations**
- **There are** 468 **stations that are ADA-compliant**
- **Proportion of station entrances/exits without vending machines is
  given by** 0.1086053

**Transposition of Route1:Route11**

``` r
Subway_Transposed = Subway %>% mutate(across(route1:route11, as.character)) %>% 
    # convert route1:route11 into character data types in order to perform the following transposition
    pivot_longer(
          cols = route1:route11,     # specify route1:route11 as original columns to transpose from
          names_to = "route_number", # column for original column names
          values_to= "route_name",   # column for original column values
          values_drop_na = TRUE      # exclude rows with NA values in "values_to" column
                )
```

- **There are** 12 **distinct stations serving the A train.**
  - **Of these serving the A train,** 10 **are ADA compliant.**

#### Problem 2

**Read-in Trash Wheel dataset sheets and clean the datasets**

``` r
# Mr.Trash-Wheel
  mr_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", range="A2:N655") %>% janitor:: clean_names() %>% mutate(sports_balls = round(as.numeric(sports_balls),0)) %>% filter(!is.na(dumpster))
# Prof.Trash-Wheel
  prof_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", sheet=2, range="A2:M123") %>% janitor::clean_names() %>% filter(!is.na(dumpster))
# Gwynnda Trash-Wheel
  gwynnda_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", sheet=4, range="A2:L266") %>% janitor::clean_names() %>% filter(!is.na(dumpster))
```

**Combine Datasets**

``` r
# Firstly add an additional column specifying the DF origin
  mr_trash_wheel = mr_trash_wheel %>% mutate(source="Mr_Trash", year=as.numeric(year))
  prof_trash_wheel = prof_trash_wheel %>% mutate(source="Prof_Trash", year=as.numeric(year))
  gwynnda_trash_wheel = gwynnda_trash_wheel %>% mutate(source="Gwynnda_Trash", year=as.numeric(year))

  combined_trash = bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) %>% relocate(source, dumpster)
```

**Discussion on the Trash Wheel Dataset**

- Trash Wheel Excel File consists of 6 sheets, of which 4 contains trash
  wheel data and the rest contains explanatory information. For the
  trash wheel relevant sheets, each consists of descriptory columns such
  as
  - **Dumpster**: the dumpster number
  - **Year/Month/Date**: the datetime info for the trash collection
  - **Weight/Volume**: size and amount of trash collected at that
    specific collection task
  - **Plastic Bottles/Polystyrene/Cigarette Butts/Glass Bottles/Plastic
    Bags/Wrappers/Sports Balls**: different genres of trash collected at
    that specific collection task
  - **Homes Powered**: number of homes could be powered by converting
    the specific amount of trash at that collection task into
    electricity
- Number of observations in each dataframe after tidy processes:
  - **mr_trash_wheel**: 651 obs with 15 variables
  - **prof_trash_wheel**: 119 obs with 14 variables
  - **gwyna_trash_wheel**: 263 obs with 13 variables
  - **combined_trash**: 1033 obs with 15 variables
- Total weight of trash collected by Professor Trash Wheel is given by:
  246.74
- Total number of cigarette butts collected by Gwynnda in June of 2022
  is given by: 1.8121^{4}

#### Problem 3

- **Component 1**: Data Cleaning for the component datasets: bakers,
  bakes, results

``` r
# Import, clean, tidy, and otherwise wrangle each of these datasets, remove observations containing empty values.
  bakers  = read.csv("../../Datasets/gbb_datasets/bakers.csv")  %>% janitor::clean_names()  %>% 
            mutate(baker_occupation=na_if(baker_occupation,""), hometown=na_if(hometown,"") ) %>% drop_na()
  bakes   = read.csv("../../Datasets/gbb_datasets/bakes.csv")   %>% janitor::clean_names()  %>%
            mutate(signature_bake=na_if(signature_bake,""), show_stopper=na_if(show_stopper,"")) %>% drop_na()
  results = read.csv("../../Datasets/gbb_datasets/results.csv", skip=2) %>% janitor::clean_names() %>%
            mutate(result=na_if(result,"")) %>% drop_na()

# Label variables that appears in multiple datasets
  bakers  = bakers %>% rename(name=baker_name, series_bakers=series, age_bakers=baker_age, 
                              occupation_bakers=baker_occupation, hometown_bakers=hometown)
  bakes   = bakes  %>% rename(name=baker, series_bakes=series, episode_bakes=episode, signature_bakes=signature_bake,
                              stopper_bakes=show_stopper)
  results = results%>% rename(name=baker, series_results=series, episode_results=episode, technical_results=technical,
                              result_results=result)

# Ensure unique identifier for each contestant
  bakers  = bakers %>% mutate(name=sub(" .*", "", name))
  
# Put unique identifier to the very front in each dataset
  bakers  = bakers %>% relocate(name)
  bakes   = bakes  %>% relocate(name)
  results = results%>% relocate(name)
```

- **Component 2**: Examine Completeness and Correctness across datasets

  - Datasets bakers, bakes, and results are all tidy after the
    data-cleaning procedures. After the cleaning processes, dataset
    bakers is complete, dataset bakes is complete, dataset results

  - 

- **Component 3**: Merge into a single, final dataset. Organize so that
  obs and var are in meaningful orders.

- **Component 4**: Export the final result into a .csv file

- **Component 5**: Description of data-cleaning process and discussion
  of final dataset

- **Component 6**: Create a reader-friendly table showing the star baker
  or winner for each episode in Season 5-10. Comment on this table -
  were there any predictable overall winders or any surprises?

- **Component 7**: Import, clean, tidy, and organize viewers.csv file.
  Show the first 10 rows of this dataset. What is the average viewership
  in Season1 and Season5 respectively?
