P8015_HW2_EZ2384
================

#### Load package

``` r
library(tidyverse)
library(tidyr)
library(dplyr)
library(readxl)
```

#### Problem 1

``` r
# Read and clean NYC Subway Data
  Subway =  read_csv("../../Datasets/NYC_Subway.csv") %>% janitor::clean_names() %>% 
            subset(select=c(line, station_latitude, station_longitude, route1:route11, entrance_type, entry, vending, ada)) %>%
            mutate(entry=case_match(entry, "YES"~"TRUE", "NO"~"FALSE"))
```

##### Dataset Description

- **Variables**
  - Division, Line, Station Name, Station Latitude, Station Longitude,
    Route1-11, Entrance Type, Entry, Exit Only, Vending, Staffing, Staff
    Hours, ADA, ADA Notes, Free Crossover, North South Street, East West
    Street, Corner, Entrance Latitude, Entrance Longitude, Station
    Location, Entrance Location
- **Discussion on Variables**
  - This dataset provides comprehensive information about subway
    stations in NYC, including spatial details, the subway routes they
    serve, and station amenities such as vending machines, ADA
    accessibility, and whether a free crossover is available.
- **Data Cleaning Steps so far**
  - Up to this point, I have firstly use the janitor package
    `clean_names` function to turn the dataset into a “nicer” format
    including turning all variable names into lowercase and replace the
    empty spaces between them with an underscore and etc. Then I
    utilized the `subset()` function to keep only variables of interest.
    Finally, I used `mutate()` in combination with `case_match()` to
    convert all instances of YES into TRUE and all instances of NO into
    FALSE within the entry column.
- **Dimension of the dataset is given by** 1868x32
- **The Dataset was originally NOT tidy**
  - Although each variable has its own column and each observation has
    its own row, there are still empty cells, which makes the dataset
    not tidy.
- **There are** 356 **distinct stations**
- **There are** 468 **stations that are ADA-compliant**
- **Proportion of station entrances/exits without vending machines is
  given by** 0.1086053

**Transposition of Route1:Route11**

``` r
Subway_Transposed = Subway %>% mutate(across(route1:route11, as.character)) %>% 
    # convert route1:route11 into character data types in order to perform the following transposition
    pivot_longer(
          cols = route1:route11,     # specify route1:route11 as original columns to transpose from
          names_to = "route_number", # column for original column names
          values_to= "route_name",   # column for original column values
          values_drop_na = TRUE      # exclude rows with NA values in "values_to" column
                )
```

- **There are** 12 **distinct stations serving the A train.**
  - **Of these serving the A train,** 10 **are ADA compliant.**

#### Problem 2

**Read-in Trash Wheel dataset sheets and clean the datasets**

``` r
# Mr.Trash-Wheel
  mr_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", range="A2:N655") %>% janitor:: clean_names() %>% mutate(sports_balls = round(as.numeric(sports_balls),0)) %>% filter(!is.na(dumpster))
# Prof.Trash-Wheel
  prof_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", sheet=2, range="A2:M123") %>% janitor::clean_names() %>% filter(!is.na(dumpster))
# Gwynnda Trash-Wheel
  gwynnda_trash_wheel = read_excel("../../Datasets/Trash_Wheel.xlsx", sheet=4, range="A2:L266") %>% janitor::clean_names() %>% filter(!is.na(dumpster))
```

**Combine Datasets**

``` r
# Firstly add an additional column specifying the DF origin
  mr_trash_wheel = mr_trash_wheel %>% mutate(source="Mr_Trash", year=as.numeric(year))
  prof_trash_wheel = prof_trash_wheel %>% mutate(source="Prof_Trash", year=as.numeric(year))
  gwynnda_trash_wheel = gwynnda_trash_wheel %>% mutate(source="Gwynnda_Trash", year=as.numeric(year))

  combined_trash = bind_rows(mr_trash_wheel, prof_trash_wheel, gwynnda_trash_wheel) %>% relocate(source, dumpster)
```

**Discussion on the Trash Wheel Dataset**

- Trash Wheel Excel File consists of 6 sheets, of which 4 contains trash
  wheel data and the rest contains explanatory information. For the
  trash wheel relevant sheets, each consists of descriptory columns such
  as
  - **Dumpster**: the dumpster number
  - **Year/Month/Date**: the datetime info for the trash collection
  - **Weight/Volume**: size and amount of trash collected at that
    specific collection task
  - **Plastic Bottles/Polystyrene/Cigarette Butts/Glass Bottles/Plastic
    Bags/Wrappers/Sports Balls**: different genres of trash collected at
    that specific collection task
  - **Homes Powered**: number of homes could be powered by converting
    the specific amount of trash at that collection task into
    electricity
- Number of observations in each dataframe after tidy processes:
  - **mr_trash_wheel**: 651 obs with 15 variables
  - **prof_trash_wheel**: 119 obs with 14 variables
  - **gwyna_trash_wheel**: 263 obs with 13 variables
  - **combined_trash**: 1033 obs with 15 variables
- Total weight of trash collected by Professor Trash Wheel is given by:
  246.74
- Total number of cigarette butts collected by Gwynnda in June of 2022
  is given by: 1.8121^{4}

#### Problem 3

- **Component 1**: Data Cleaning for the component datasets: bakers,
  bakes, results

``` r
# Import, clean, tidy, and otherwise wrangle each of these datasets, remove observations containing empty values.
  bakers  = read.csv("../../Datasets/gbb_datasets/bakers.csv")  %>% janitor::clean_names()  %>% 
            mutate(baker_occupation=na_if(baker_occupation,""), hometown=na_if(hometown,"") ) %>% drop_na()
  bakes   = read.csv("../../Datasets/gbb_datasets/bakes.csv")   %>% janitor::clean_names()  %>%
            mutate(signature_bake=na_if(signature_bake,""), show_stopper=na_if(show_stopper,"")) %>% drop_na()
  results = read.csv("../../Datasets/gbb_datasets/results.csv", skip=2) %>% janitor::clean_names() %>%
            mutate(result=na_if(result,"")) %>% drop_na()

# Label variables that appears in multiple datasets
  bakers  = bakers %>% rename(name=baker_name, series_bakers=series, age_bakers=baker_age, 
                              occupation_bakers=baker_occupation, hometown_bakers=hometown)
  bakes   = bakes  %>% rename(name=baker, series_bakes=series, episode_bakes=episode, signature_bakes=signature_bake,
                              stopper_bakes=show_stopper)
  results = results%>% rename(name=baker, series_results=series, episode_results=episode, technical_results=technical,
                              result_results=result)

# Ensure unique identifier for each contestant
  bakers  = bakers %>% mutate(name=sub(" .*", "", name))
  
# Put unique identifier to the very front in each dataset
  bakers  = bakers %>% relocate(name)
  bakes   = bakes  %>% relocate(name)
  results = results%>% relocate(name)
```

- **Component 2**: Examine Completeness and Correctness across datasets
  - Datasets bakers, bakes, and results are all tidy after the
    data-cleaning procedures. After the cleaning processes, dataset
    bakers and results are complete. Dataset bakes is largely complete
    except it contains some “UNKNOWN” show_stoppers.

  - Matching status of key variable:

    - Contestants included in bakers dataset that are not included in
      the results dataset is given by Jo
    - Contestants included in bakers dataset that are not included in
      the bakes dataset is given by Alice, Amelia, Antony, Briony, Dan,
      Dan, Helena, Henry, Imelda, Jamie, Jo, Jon, Karen, Kim-Joy, Luke,
      Manon, Michelle, Phil, Priya, Rahul, Rosie, Steph, Terry
- **Component 3**: Merge into a single, final dataset. Organize so that
  obs and var are in meaningful orders.

``` r
  merged <- bakers %>% left_join(bakes, by = "name") %>% left_join(results, by = "name")
```

    ## Warning in left_join(., bakes, by = "name"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 1 of `x` matches multiple rows in `y`.
    ## ℹ Row 2 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

    ## Warning in left_join(., results, by = "name"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 1 of `x` matches multiple rows in `y`.
    ## ℹ Row 166 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

``` r
  merged = merged %>% relocate(name, result_results, technical_results, starts_with("series"), starts_with("episode")) %>%
           arrange(name, result_results, technical_results)
```

- **Component 4**: Export the final result into a .csv file

``` r
  write.csv(merged, "C:/Users/Twilight/Desktop/Columbia/Fall Semester 2024/Data Science I/HWs/p8105_hw2_ez2384/merged.csv")
```

- **Component 5**: Description of data-cleaning process and discussion
  of final dataset

  **clean the component datasets bakes, bakers, and results**

1.  used janitor package clean_names() to convert variable names into
    meaningful format
2.  converted all empty strings in character data type columns into NA
    to faciliate my later removal of all NA records
3.  dropped all NA records
4.  added postfixes to each datasets to faciliate future merging
5.  relocate name (the unique identifier) to the very front  
    **merge datasets**
6.  merge datasets by the unique identifier – name
7.  relocate variable locations by name, results, technical_results,
    series_number, episode_number, etc.
8.  sort variables by name, results, technical_scores

- **Component 6**: Create a reader-friendly table showing the star baker
  or winner for each episode in Season 5-10. Comment on this table -
  were there any predictable overall winners or any surprises?

``` r
  winners = merged %>%  select(name, result_results, starts_with("series"), starts_with("episode")) %>%
                        filter(result_results %in% c("Runner-up", "STAR BAKER", "WINNER")) %>%
                        filter(series_bakes %in% c(5:10) & series_results %in% c(5:10) & series_bakers %in% c(5:10)) %>%
                        arrange()

  winners = winners %>% pivot_longer(
                          cols=c("series_bakers", "series_bakes", "series_results"),
                          names_to = "orig_series_names",
                          values_to= "series",
                          values_drop_na = TRUE
                    )
  
  winners = winners %>% pivot_longer(
                          cols=c("episode_bakes", "episode_results"),
                          names_to = "orig_episode_names",
                          values_to= "episodes",
                          values_drop_na = TRUE
                    )
  winners = winners %>% select(-orig_series_names, -orig_episode_names) %>% arrange()





  winner_frequency = winners %>% count(name) %>% arrange(desc(n))
  
  star_baker = winners %>% filter(result_results=="STAR BAKER")
  star_baker_names = distinct(star_baker, name)
```

- According to winner_frequency we can see that Kate is predominately
  winning (with 1197 occurrences of succeeding or winning). the second
  predominately winner has a drastically lower frequency of 198,
  therefore it is not surprising at all when we examine the list of star
  bakers in the star_baker_name dataset that we see Kate and Tom within
  the list.

- However, it is quite surprising to see that Marie appeared in the list
  given she only has a succeeding occurrences of 2

- **Component 7**: Import, clean, tidy, and organize viewers.csv file.
  Show the first 10 rows of this dataset. What is the average viewership
  in Season1 and Season5 respectively?

``` r
  viewers = read.csv("../../Datasets/gbb_datasets/viewers.csv") %>% janitor::clean_names() %>% arrange()
  # Ten observations given by
  head(viewers, n=10)
```

    ##    episode series_1 series_2 series_3 series_4 series_5 series_6 series_7
    ## 1        1     2.24     3.10     3.85     6.60    8.510    11.62    13.58
    ## 2        2     3.00     3.53     4.60     6.65    8.790    11.59    13.45
    ## 3        3     3.00     3.82     4.53     7.17    9.280    12.01    13.01
    ## 4        4     2.60     3.60     4.71     6.82   10.250    12.36    13.29
    ## 5        5     3.03     3.83     4.61     6.95    9.950    12.39    13.12
    ## 6        6     2.75     4.25     4.82     7.32   10.130    12.00    13.13
    ## 7        7       NA     4.42     5.10     7.76   10.280    12.35    13.45
    ## 8        8       NA     5.06     5.35     7.41    9.023    11.09    13.26
    ## 9        9       NA       NA     5.70     7.41   10.670    12.65    13.44
    ## 10      10       NA       NA     6.74     9.45   13.510    15.05    15.90
    ##    series_8 series_9 series_10
    ## 1      9.46     9.55      9.62
    ## 2      9.23     9.31      9.38
    ## 3      8.68     8.91      8.94
    ## 4      8.55     8.88      8.96
    ## 5      8.61     8.67      9.26
    ## 6      8.61     8.91      8.70
    ## 7      9.01     9.22      8.98
    ## 8      8.95     9.69      9.19
    ## 9      9.03     9.50      9.34
    ## 10    10.04    10.34     10.05

- Average viewership in Season1 is given by 2.77
- Average viewership in Season5 is given by 10.0393

`r`
